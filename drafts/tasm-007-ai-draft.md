# Unraveling the Web of AI: Insights from the Toronto AI Safety Group Meeting

## Pre-meeting Chat: The CS Cabal's Stealthy Presence

Before delving into the depths of Artificial Intelligence (AI), the Toronto AI Safety Group had a casual chat, shedding light on the Toronto Computer Science Cabal, also known as the Toronto CS reading group. This community, with a lively online presence at http://compscicabal.github.io/, is not a mysterious organization but rather a gathering of enthusiasts keen on exploring the intricacies of computer science. I highlighted their presence because there might be an interest in the overlap between the Toronto CS Cabal and the AI safety group. As these two groups navigate their respective domains, potential synergies and collaborative opportunities could emerge, fostering a richer understanding of AI safety within the broader computer science community.

## AI Update: From Supercomputers to Brain Chips

In the AI Update segment, headlines sparked conversations, and intriguing possibilities emerged:

1. **Bengio's Bold Proposition:** [Yoshua Bengio urges Canada](https://www.cbc.ca/news/canada/montreal/bengio-asks-canada-to-build-ai-supercomputer-1.7094858) to invest $1 billion in a public supercomputer dedicated to AI. This proposal triggers thoughts on the tradeoffs between investing in cutting-edge hardware and its rapid depreciation. Note to self: consider buying shares in Nvidia and AMD.

2. **Neuralink's Mind-Boggling Move:** Elon Musk claimed that [Neuralink implanted a wireless brain chip](https://www.bbc.com/news/technology-68137046). The implications of merging human brains with AI technology raise ethical questions and futuristic scenarios. Is this the dawn of a new era, or are we tiptoeing into a sci-fi nightmare?

3. **AI Spam Takes the Stage:** The dark side of AI emerges as [AI-generated spam](https://www.businessinsider.com/ai-spam-google-ruin-internet-search-scams-chatgpt-2024-1) starts infiltrating the internet. However, the room debates the consensus on this issue, questioning the credibility of sources like Business Insider. Could NFTs provide a shield against AI spam? The room is divided, echoing the sentiments captured by the classic XKCD comic on the matter ([XKCD 810](https://xkcd.com/810/)).

## The Talk - Honest AI: Peeling Back the Layers of Deception

Now, onto the main event - the discussion on Honest AI. The room delves into the [arXiv paper](https://arxiv.org/abs/2310.01405) and Scott Alexander's coverage at [Astral Codex Ten](https://www.astralcodexten.com/p/the-road-to-honest-ai).

### Unveiling the Black Box

The talk revolves around catching an AI liar and understanding its honesty. The paper explores concepts such as [lie detection in Black Box LLMs](https://www.lesswrong.com/posts/khFC2a4pLPvGtXAGG/how-to-catch-an-ai-liar-lie-detection-in-black-box-llms-by), [monosemantic features](https://transformer-circuits.pub/2023/monosemantic-features/index.html), and [activation clustering](https://www.alignmentforum.org/posts/cLfsabkCPtieJ5LoK/investigating-bias-representations-in-llms-via-activation). Principal Component Analysis (PCA) and K-means clustering emerge as unsupervised learning techniques, wielding the power to unravel the secrets within the AI black box.

### The Dance of Deception

#### Honesty vs. Truthfulness

Distinguishing between honesty and truthfulness becomes crucial. No model is omniscient, making these two concepts distinct. Truthfulness focuses on stating factually true things, while honesty reflects the model's beliefs, even if flawed. The room grapples with the intricate dance between honest statements and truthful ones, realizing the potential for statements that are honest yet not truthful, and vice versa.

#### Deception Unveiled

Beyond direct lies, the detector detects hallucinations and misleading information. The discussion extends to concepts like situational awareness, temporal understanding, and biases lurking beneath the surface. The intricacies of bias, both visible and invisible to the model, pose challenges that demand further exploration.

## Illuminating Bias Representations

Post-meeting, the group engages with [insights on bias representations in LLMs](https://www.lesswrong.com/posts/cLfsabkCPtieJ5LoK/investigating-bias-representations-in-llms-via-activation). The investigation into biases, both discernible and hidden, adds a layer of complexity to the AI ethics conversation. Understanding these biases is pivotal in building AI systems that navigate the ethical landscape responsibly.

In conclusion, the Toronto AI Safety Group meeting offered a glimpse into the evolving landscape of AI, from grand proposals to potential brain-chip revolutions and the nuanced dance between honesty and truthfulness. As we continue to unravel the mysteries within the AI black box, one thing remains certain â€“ the journey is as complex as the technology itself.

![AI-Lies.png](An artistic representation of deceptive AI, with intricate circuitry weaving a web of lies, symbolizing the challenges in uncovering hidden truths within the AI black box.)
